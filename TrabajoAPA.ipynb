{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1> <font style=\"bold\"> Analisis Predictivo Avanzado </font></h1>\n",
    "    <h2><font style=\"bold\">Trabajo pr치ctico </font></h2>\n",
    "    <h3><font style=\"bold\">Integrantes:</font></h3>\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <h4><ul>\n",
    "        <li>Noguera Abril</li>\n",
    "        <li>Arbues Lucas</li>\n",
    "        <li>Alfie Agustin</li>\n",
    "        </ul>\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Funciones: \n",
    "from funciones import encoding, balance, Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOHE = encoding(df[['category_id', 'domain_id', 'item_id','name','conversion','ROW_ID']], ['category_id', 'domain_id', 'item_id','name'], 'TE').merge(\n",
    "    encoding(df.drop(['category_id', 'domain_id', 'item_id','name','conversion'], axis=1), ['listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], 'OHE'), \n",
    "    left_index=True, right_index=True, how='inner')\n",
    "dfOHE['ROW_ID'] = dfOHE['ROW_ID_x']\n",
    "dfOHE =dfOHE.drop(['ROW_ID_x','ROW_ID_y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLE = encoding(df, ['category_id', 'domain_id', 'item_id','name', 'listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], 'LE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOE = encoding(df, ['category_id', 'domain_id', 'item_id','name', 'listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], 'OE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFE = encoding(df, ['category_id', 'domain_id', 'item_id','name', 'listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], 'FE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTE = encoding(df, ['category_id', 'domain_id', 'item_id','name', 'listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], 'TE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploraci칩n e Implementaci칩n del Modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez finalizado el analisis exploratorio de datos (EDA), se procede a la exploracion e implementacion del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train: 80%\n",
    "- Val: 20%\n",
    "- Test: de testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfOHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and evaluation samples\n",
    "train_data = df[df[\"ROW_ID\"].isna()]\n",
    "test_data = df[df[\"ROW_ID\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=[\"ROW_ID\"])\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data.drop(columns=[\"conversion\"]), train_data['conversion'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(columns=[\"conversion\", \"ROW_ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion\n",
      "False    131196\n",
      "True      13412\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((y_train == 1).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS, US, LT, NM y SM\n",
    "X_train, y_train = balance(X_train, y_train, 'NM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizaci칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1, verbose=1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "            'max_depth': stats.randint(1,20),\n",
    "              'n_estimators': stats.randint(10, 200),\n",
    "              'min_samples_split': stats.randint(2, 20),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {\n",
    "    'n_estimators': (10, 200),\n",
    "    'max_depth': (1, 32),\n",
    "    'min_samples_split': (2, 20),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimization(model=model, param_grid=grid, n_iter=10, cv=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "RS = optimizer.random_search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters (Random Search): {'max_depth': 7, 'min_samples_split': 16, 'n_estimators': 156}\n"
     ]
    }
   ],
   "source": [
    "best_params_random = RS.best_params_\n",
    "print(\"Best hyperparameters (Random Search):\", best_params_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7404699738903394"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19211 entries, 180761 to 199971\n",
      "Data columns (total 81 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   category_id                         18733 non-null  float64\n",
      " 1   domain_id                           18971 non-null  float64\n",
      " 2   item_id                             0 non-null      float64\n",
      " 3   name                                19211 non-null  float64\n",
      " 4   available_quantity                  19211 non-null  int64  \n",
      " 5   avg_gmv_item_domain_30days          19211 non-null  float64\n",
      " 6   avg_gmv_item_sel                    19211 non-null  float64\n",
      " 7   avg_gmv_seller_bday                 19211 non-null  float64\n",
      " 8   avg_qty_orders_item_domain_30days   19211 non-null  float64\n",
      " 9   avg_qty_orders_item_sel_30days      19211 non-null  float64\n",
      " 10  avg_si_item_sel_30day               19211 non-null  float64\n",
      " 11  free_shipping                       19211 non-null  bool   \n",
      " 12  fulfillment                         19211 non-null  bool   \n",
      " 13  health                              19211 non-null  float64\n",
      " 14  offset                              19211 non-null  int64  \n",
      " 15  original_price                      19211 non-null  int64  \n",
      " 16  price                               19211 non-null  int64  \n",
      " 17  print_position                      19211 non-null  int64  \n",
      " 18  qty_items_dom                       19211 non-null  float64\n",
      " 19  qty_items_sel                       19211 non-null  float64\n",
      " 20  sold_quantity                       19211 non-null  int64  \n",
      " 21  total_asp_item_domain_30days        19211 non-null  float64\n",
      " 22  total_asp_item_sel_30days           19211 non-null  float64\n",
      " 23  total_gmv_item_30days               19211 non-null  float64\n",
      " 24  total_items_domain                  19211 non-null  int64  \n",
      " 25  total_items_seller                  19211 non-null  int64  \n",
      " 26  total_orders_domain_30days          19211 non-null  float64\n",
      " 27  total_orders_item_30days            19211 non-null  float64\n",
      " 28  total_orders_sel_30days             19211 non-null  float64\n",
      " 29  total_si_domain_30days              19211 non-null  float64\n",
      " 30  total_si_item_30days                19211 non-null  float64\n",
      " 31  total_si_sel_30days                 19211 non-null  float64\n",
      " 32  total_visits_domain                 19211 non-null  int64  \n",
      " 33  total_visits_item                   19211 non-null  int64  \n",
      " 34  total_visits_seller                 19211 non-null  int64  \n",
      " 35  price_ratio                         19211 non-null  float64\n",
      " 36  platform_web                        19211 non-null  bool   \n",
      " 37  ahora-12                            19211 non-null  int64  \n",
      " 38  brand_verified                      19211 non-null  int64  \n",
      " 39  cart_eligible                       19211 non-null  int64  \n",
      " 40  catalog_listing_eligible            19211 non-null  int64  \n",
      " 41  deal_of_the_day                     19211 non-null  int64  \n",
      " 42  dragged_bids_and_visits             19211 non-null  int64  \n",
      " 43  extended_warranty_eligible          19211 non-null  int64  \n",
      " 44  good_quality_picture                19211 non-null  int64  \n",
      " 45  good_quality_thumbnail              19211 non-null  int64  \n",
      " 46  immediate_payment                   19211 non-null  int64  \n",
      " 47  incomplete_technical_specs          19211 non-null  int64  \n",
      " 48  lightning_deal                      19211 non-null  int64  \n",
      " 49  loyalty_discount_eligible           19211 non-null  int64  \n",
      " 50  poor_quality_picture                19211 non-null  int64  \n",
      " 51  poor_quality_thumbnail              19211 non-null  int64  \n",
      " 52  supermarket_eligible                19211 non-null  int64  \n",
      " 53  today_promotion                     19211 non-null  int64  \n",
      " 54  under_infractions                   19211 non-null  int64  \n",
      " 55  hour_sin                            19211 non-null  float64\n",
      " 56  hour_cos                            19211 non-null  float64\n",
      " 57  weekday_sin                         19211 non-null  float64\n",
      " 58  weekday_cos                         19211 non-null  float64\n",
      " 59  day_sin                             19211 non-null  float64\n",
      " 60  day_cos                             19211 non-null  float64\n",
      " 61  listing_type_id_gold_pro            19211 non-null  bool   \n",
      " 62  listing_type_id_gold_special        19211 non-null  bool   \n",
      " 63  logistic_type_cross_docking         19211 non-null  bool   \n",
      " 64  logistic_type_custom                19211 non-null  bool   \n",
      " 65  logistic_type_default               19211 non-null  bool   \n",
      " 66  logistic_type_drop_off              19211 non-null  bool   \n",
      " 67  logistic_type_fulfillment           19211 non-null  bool   \n",
      " 68  logistic_type_not_specified         19211 non-null  bool   \n",
      " 69  logistic_type_xd_drop_off           19211 non-null  bool   \n",
      " 70  platform_/mobile/android            19211 non-null  bool   \n",
      " 71  platform_/mobile/ios                19211 non-null  bool   \n",
      " 72  platform_/web/desktop               19211 non-null  bool   \n",
      " 73  platform_/web/mobile                19211 non-null  bool   \n",
      " 74  cat_warranty_garantia               19211 non-null  bool   \n",
      " 75  cat_warranty_garantia de fabrica    19211 non-null  bool   \n",
      " 76  cat_warranty_garantia del vendedor  19211 non-null  bool   \n",
      " 77  cat_warranty_sin garantia           19211 non-null  bool   \n",
      " 78  is_pdp_False                        19211 non-null  bool   \n",
      " 79  is_pdp_True                         19211 non-null  bool   \n",
      " 80  is_pdp_nan                          19211 non-null  bool   \n",
      "dtypes: bool(23), float64(29), int64(29)\n",
      "memory usage: 9.1 MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/anoguera/Documents/GitHub/TrabajoAPA/TrabajoAPA.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anoguera/Documents/GitHub/TrabajoAPA/TrabajoAPA.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Predict on the evaluation set\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anoguera/Documents/GitHub/TrabajoAPA/TrabajoAPA.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred \u001b[39m=\u001b[39m RS\u001b[39m.\u001b[39;49mpredict_proba(X_test)[:,\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anoguera/Documents/GitHub/TrabajoAPA/TrabajoAPA.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_pred\n",
      "File \u001b[0;32m~/anaconda3/envs/itba_apa_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:542\u001b[0m, in \u001b[0;36mBaseSearchCV.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call predict_proba on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \n\u001b[1;32m    525\u001b[0m \u001b[39mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m    to that in the fitted attribute :term:`classes_`.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 542\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mpredict_proba(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/itba_apa_env/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/anaconda3/envs/itba_apa_env/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/itba_apa_env/lib/python3.8/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/itba_apa_env/lib/python3.8/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/envs/itba_apa_env/lib/python3.8/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/itba_apa_env/lib/python3.8/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Predict on the evaluation set\n",
    "y_pred = RS.predict_proba(X_test)[:,1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the submission file\n",
    "submission_df = pd.DataFrame({\"ROW_ID\": test_data[\"ROW_ID\"], \"conversion\": y_pred})\n",
    "submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "submission_df.to_csv(\"xg_boostRS.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itba_apa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
