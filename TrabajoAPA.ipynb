{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1> <font style=\"bold\"> Analisis Predictivo Avanzado </font></h1>\n",
    "    <h2><font style=\"bold\">Trabajo práctico </font></h2>\n",
    "    <h3><font style=\"bold\">Integrantes:</font></h3>\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <h4><ul>\n",
    "        <li>Noguera Abril</li>\n",
    "        <li>Arbues Lucas</li>\n",
    "        <li>Alfie Agustin</li>\n",
    "        </ul>\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Funciones: \n",
    "from funciones import encoding, balance, Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['conversion'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ROW_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180761, 68)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración e Implementación del Modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez finalizado el analisis exploratorio de datos (EDA), se procede a la exploracion e implementacion del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train: 80%\n",
    "- Val: 20%\n",
    "- Test: de testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train.reset_index(inplace=True,drop=True)\n",
    "test.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una instancia del MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Variables a Escalar\n",
    "var_num = train.select_dtypes(include='number')\n",
    "var_num = var_num.drop(['conversion'], axis =1)\n",
    "var_num = var_num.columns\n",
    "\n",
    "# Ajusta y transforma tus datos de entrenamiento\n",
    "train[var_num] = scaler.fit_transform(train[var_num])\n",
    "\n",
    "# Transforma tus datos de prueba\n",
    "test[var_num]= scaler.transform(test[var_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = train[['category_id', 'domain_id', 'item_id','name', 'listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp','conversion']]\n",
    "train = train.drop(['category_id', 'domain_id', 'item_id','name', 'listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp','conversion'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded = test[['category_id', 'domain_id', 'item_id','name', 'listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp','conversion']]\n",
    "test = test.drop(['category_id', 'domain_id', 'item_id','name', 'listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp','conversion'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTE, testTE = encoding(train_encoded[['category_id', 'domain_id', 'item_id','name','conversion']],\n",
    "                           test_encoded[['category_id', 'domain_id', 'item_id','name','conversion']],\n",
    "                            ['category_id', 'domain_id', 'item_id', 'name'], \n",
    "                            'TE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = train_encoded.drop(['category_id', 'domain_id', 'item_id','name','conversion'], axis=1)\n",
    "test_encoded = test_encoded.drop(['category_id', 'domain_id', 'item_id','name','conversion'], axis=1)\n",
    "trainOHE, testOHE = encoding(train_encoded,\n",
    "                           test_encoded,\n",
    "                            ['listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], \n",
    "                            'OHE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(trainTE, left_index=True, right_index=True, how='inner')\n",
    "train = train.merge(trainOHE, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(testTE, left_index=True, right_index=True, how='inner')\n",
    "test = test.merge(testOHE, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['conversion']\n",
    "X_train = train.drop(['conversion'], axis = 1)\n",
    "y_test = test['conversion']\n",
    "X_test = test.drop(['conversion'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfOHE = encoding(df[['category_id', 'domain_id', 'item_id','name','conversion','ROW_ID']], ['category_id', 'domain_id', 'item_id','name'], 'TE').merge(\n",
    "#     encoding(df.drop(['category_id', 'domain_id', 'item_id','name','conversion'], axis=1), ['listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], 'OHE'), \n",
    "#     left_index=True, right_index=True, how='inner')\n",
    "# dfOHE['ROW_ID'] = dfOHE['ROW_ID_x']\n",
    "# dfOHE =dfOHE.drop(['ROW_ID_x','ROW_ID_y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfLE = encoding(df[['category_id', 'domain_id', 'item_id','name','conversion','ROW_ID']], ['category_id', 'domain_id', 'item_id','name'], 'TE').merge(\n",
    "#     encoding(df.drop(['category_id', 'domain_id', 'item_id','name','conversion'], axis=1), ['listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], 'LE'), \n",
    "#     left_index=True, right_index=True, how='inner')\n",
    "# dfLE['ROW_ID'] = dfLE['ROW_ID_x']\n",
    "# dfLE = dfLE.drop(['ROW_ID_x','ROW_ID_y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfOE = encoding(df[['category_id', 'domain_id', 'item_id','name','conversion','ROW_ID']], ['category_id', 'domain_id', 'item_id','name'], 'TE').merge(\n",
    "#     encoding(df.drop(['category_id', 'domain_id', 'item_id','name','conversion'], axis=1), ['listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], 'OE'), \n",
    "#     left_index=True, right_index=True, how='inner')\n",
    "# dfOE['ROW_ID'] = dfOE['ROW_ID_x']\n",
    "# dfOE = dfOE.drop(['ROW_ID_x','ROW_ID_y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfFE = encoding(df, ['category_id', 'domain_id', 'item_id','name', 'listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], 'FE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTE = encoding(df, ['category_id', 'domain_id', 'item_id','name', 'listing_type_id', 'logistic_type', 'platform', 'cat_warranty', 'is_pdp'], 'TE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion\n",
      "False    131298\n",
      "True      13310\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((y_train == 1).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS, US, LT, NM y SM\n",
    "X_train, y_train = balance(X_train, y_train, 'LT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion\n",
      "False    126917\n",
      "True      13310\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((y_train == 1).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1, verbose=1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "         'n_estimators': np.arange(10, 200, 10),  # Número de árboles en el bosque\n",
    "          'max_features': ['auto', 'sqrt', 'log2'],  # Número de características a considerar en cada split\n",
    "          'max_depth': np.arange(1, 20),  # Profundidad máxima del árbol\n",
    "          'min_samples_split': np.arange(2, 20),  # Número mínimo de muestras requeridas para dividir un nodo\n",
    "          'min_samples_leaf': np.arange(1, 20),  # Número mínimo de muestras requeridas en un nodo hoja\n",
    "          'bootstrap': [True, False],  # Método para muestrear instancias de entrenamiento (con o sin reemplazo)\n",
    "          'criterion': ['gini', 'entropy']  # Función para medir la calidad de una división\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimization(model=model, param_grid=grid, n_iter=10, cv=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "RS = optimizer.random_search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters (Random Search): {'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'max_depth': 16, 'criterion': 'entropy', 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "best_params_random = RS.best_params_\n",
    "print(\"Best hyperparameters (Random Search):\", best_params_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9154656496311798"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 190 out of 190 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "y_proba = RS.predict(X_test)\n",
    "y_pred = (y_proba >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.37      0.53     32719\n",
      "         1.0       0.12      0.80      0.21      3434\n",
      "\n",
      "    accuracy                           0.41     36153\n",
      "   macro avg       0.53      0.59      0.37     36153\n",
      "weighted avg       0.87      0.41      0.50     36153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9081404032860344\n",
      "Recall: 0.1432731508444962\n",
      "Specificity: 0.9884165163972004\n"
     ]
    }
   ],
   "source": [
    "# Calculamos Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculamos Recall\n",
    "recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# Calculamos Specificity\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(best_estimator)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Create a summary plot\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'max_depth': stats.randint(1,20),\n",
    "              'learning_rate': stats.uniform(0.01, 0.5),\n",
    "              'subsample': stats.uniform(0.1, 1),\n",
    "              'colsample_bytree': stats.uniform(0.1, 1),\n",
    "              'min_child_weight': stats.randint(1,4),\n",
    "              'n_estimators': stats.randint(50, 1000)\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimization(model=model, param_grid=grid, n_iter=10, cv=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "RS = optimizer.random_search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters (Random Search): {'colsample_bytree': 0.2559945203362026, 'learning_rate': 0.03904180608409973, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 711, 'subsample': 0.15641157902710026}\n"
     ]
    }
   ],
   "source": [
    "best_params_random = RS.best_params_\n",
    "print(\"Best hyperparameters (Random Search):\", best_params_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7625130125682886"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = RS.predict(X_test)\n",
    "y_pred = (y_proba >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.37      0.53     32719\n",
      "         1.0       0.12      0.80      0.21      3434\n",
      "\n",
      "    accuracy                           0.41     36153\n",
      "   macro avg       0.53      0.59      0.37     36153\n",
      "weighted avg       0.87      0.41      0.50     36153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9081404032860344\n",
      "Recall: 0.1432731508444962\n",
      "Specificity: 0.9884165163972004\n"
     ]
    }
   ],
   "source": [
    "# Calculamos Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculamos Recall\n",
    "recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# Calculamos Specificity\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(best_estimator)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Create a summary plot\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para LGBM\n",
    "param_dist = {\n",
    "    'num_leaves': stats.randint(6, 50), \n",
    "    'min_child_samples': stats.randint(100, 500), \n",
    "    'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "    'subsample': stats.uniform(loc=0.2, scale=0.8), \n",
    "    'colsample_bytree': stats.uniform(loc=0.4, scale=0.6),\n",
    "    'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "    'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100],\n",
    "    'n_estimators': stats.randint(1000, 2000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear modelo LGBM\n",
    "clf = lgbm.LGBMClassifier(max_depth=-1, random_state=34, metric='None', n_jobs=-1, class_weight='balanced', \n",
    "                         scale_pos_weight = sum(y_train == 0) / sum(y_train == 1), boost_from_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Búsqueda aleatoria\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=10, cv=kf, scoring='roc_auc', n_jobs=-1, random_state=22)\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6626083960492597,\n",
       " 'min_child_samples': 310,\n",
       " 'min_child_weight': 0.1,\n",
       " 'n_estimators': 1390,\n",
       " 'num_leaves': 21,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 100,\n",
       " 'subsample': 0.7259942658487797}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_search.best_params_ \n",
    "\n",
    "# {'colsample_bytree': 0.6626083960492597,\n",
    "#  'min_child_samples': 310,\n",
    "#  'min_child_weight': 0.1,\n",
    "#  'n_estimators': 1390,\n",
    "#  'num_leaves': 21,\n",
    "#  'reg_alpha': 0,\n",
    "#  'reg_lambda': 100,\n",
    "#  'subsample': 0.7259942658487797}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8983421747089089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_search.best_score_ # 0.8984360454300557"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itba_apa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
